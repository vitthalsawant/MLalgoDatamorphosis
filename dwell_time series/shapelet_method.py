# -*- coding: utf-8 -*-
"""shapelet_method

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/vitthalsawant/shapelet-method.96cc8620-d06e-474b-abd4-16cec5c0d041.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20251229/auto/storage/goog4_request%26X-Goog-Date%3D20251229T210806Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D0dd6cdd803ac0675bff44d5f0189caa707a464c7876c541569c262f38a579ca11ceb98f3238699df43b5dda26513127dcc0f71792eac4ba29298d8a70bfd5ed75ca1719a31491f716173254a3e3169c115d4eb047d96c330812d0546bf3c5890507569069acac2f522f6c67290a1b1a545828b735b2fb686cad35c1744eb81c5c4792945ff6f2ea449a45d7e713db3fba49cf0f2c3b61934c5db172e70bcb0ab5bdd8df8bea8d9b4e6c03d00d9ccdd45671f7ecd751e97ca2002a7a6a11084adc1e3e9f76d8e2614fa4c54acbf8b91a29fb7cf37daf7d2883857db5af93465b027da33fd8fb412c523eb82f3a3b6ea2cf68584dbc08bca6ee1844d28c3245354
"""

# Data is located locally in the dwell-time2 folder
# Install required package if not already installed
# ! pip install tslearn

import numpy as np
import pandas as pd
from glob import glob
import os
from sklearn.preprocessing import MinMaxScaler

from tensorflow.python.client import device_lib
from tensorflow.keras.optimizers import Adam

from tslearn.shapelets import LearningShapelets
from tslearn.preprocessing import TimeSeriesScalerMinMax

from sklearn.metrics import confusion_matrix
from sklearn.model_selection import train_test_split

import random

import matplotlib.pyplot as plt
import matplotlib
import seaborn as sns
sns.set_theme()

# Visitor tracking with live camera
import cv2
from datetime import datetime, timedelta
from collections import defaultdict
import threading
import time

"""# 1. Time series preprocessing

<h3> a) Functions responsible for the time series segmentation </h3>
"""

def divide(data, length, stride):
    '''
    data: numpy array containing the dwell times series data
    length: length of the subseries after segmentation
    stride: space (in points) between beginnings of two consecutive subseries
    '''
    rslt = []
    i = 0
    while (i * stride < len(data) - length):
        piece = data[i * stride:(i * stride + length)]
        i += 1
        rslt.append(piece)
    return np.array(rslt)

def load(dir, length, stride):
    data0 = pd.read_csv(dir[0], header=None).values # data0 - data obtained from first file in the directory
    data0_div = divide(data0, length, stride)
    for j in range(1, len(dir)):
        data = pd.read_csv(dir[j], header=None).values # data - data obtained from the file numbered with i in a given directory dir
        data_div = divide(data, length, stride)
        data0_div = np.concatenate((data0_div, data_div)) # concatenating data obtained from different files
    return data0_div.reshape(data0_div.shape[:2]) # reshaping the data

"""<h3>b) The data normalization </h3>"""

def data_preprocessing (dirs, length, stride):
    ''' calculation of the length of the time series of each type in order to abbreviate them to the same length (avoiding class imbalance problem) '''
    lengths = []
    for i in range(len(dirs)):
        ts = load(dirs[i], length, stride)
        lengths.append(len(ts))

    min_length = min(lengths)
    ''' scaling the data to the [0, 1] range '''

    data = []

    for i in range(len(dirs)):
        ts = load(dirs[i], length, stride)[:min_length]
        sc = MinMaxScaler() # MiMaxScaler of the dwell time series data
        ts_sc = sc.fit_transform(ts)
        data.append(ts_sc)
    ''' concatenation of data '''
    X = np.vstack(data)

    ''' creating the labels of the data '''
    y = np.concatenate((np.zeros(min_length), np.ones(min_length)))

    return X, y

"""# 2. The training process

<h3> a) Verification of the available GPUs on the machine </h3>
"""

def get_available_gpus():
    local_device_protos = device_lib.list_local_devices()
    return [x.name for x in local_device_protos if x.device_type == 'GPU']

"""<h3> b) Loading the data - choice of the group of data to be processed </h3>"""

possibilities = ["naringenina", "voltage"]
choice = "naringenina"

n = 2
length = 50
stride = 50

# Get the base directory path (assuming script is in the same directory as dwell-time2)
base_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "dwell-time2")

if(choice == "naringenina"):
    dirs_naringenina10 = glob(os.path.join(base_dir, "naringenina/60_10/*.txt"))
    dirs_naringenina0 = glob(os.path.join(base_dir, "naringenina/60_0/*.txt"))

    X, y = data_preprocessing([dirs_naringenina0, dirs_naringenina10], length, stride)

elif(choice == "voltage"):
    dirs_voltage60 = glob(os.path.join(base_dir, "voltage/60_10/*.txt"))
    dirs_voltage20 = glob(os.path.join(base_dir, "voltage/20_10/*.txt"))

    X, y = data_preprocessing([dirs_voltage60, dirs_voltage20], length, stride)

"""<h3> c) Cross validation step </h3>"""

cm_start = np.zeros((n, n)) # confusion matrix fulfilled all with zeros (n is the number of classes)
states = random.sample(range(0, 1000), 40) # random state for generation of the new X_train, X_test datasets during each cross-validation step

# Create results directory if it doesn't exist
results_dir = "rslt/" + choice
os.makedirs(results_dir, exist_ok=True)

acc = 0
for k in range(1):
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=states[k]) # split of the data to the training and testing datasets

        shp_clf = LearningShapelets(n_shapelets_per_size={20: 10},
                                    weight_regularizer=0.001,
                                    optimizer=Adam(learning_rate=0.01),
                                    max_iter=200,
                                    verbose=0,
                                    scale=False,
                                    random_state=42) # instance of LearningShapelet class

        shp_clf.fit(X_train, y_train) # training
        y_pred = shp_clf.predict(X_test) # testing
        cm = confusion_matrix(y_test, y_pred) # confusion matrix for the given cross-validation step (corrected argument order)
        acc_new = np.sum(np.diagonal(cm)) / np.sum(cm) # calculation of accuracy
        ''' choice of the cross validation step for which the best performance of algorithm is obtained (for the visualisation purposes) '''
        if(acc_new > acc):
            distances = shp_clf.transform(X_train) # data transformed to the space of distances to the shapelets
            np.savetxt("dist.txt", distances)
            predicted_locations = shp_clf.locate(X_train)
            np.savetxt("pred_loc.txt", predicted_locations)
            weights, biases = shp_clf.get_weights('classification')
            np.savetxt("weights.txt", weights)
            np.savetxt("biases.txt", biases)
            np.savetxt("X_train.txt", X_train.reshape(X_train.shape[:2]))
            np.savetxt("y_train.txt", y_train)
            acc = acc_new
            for m in range(10):
                shap = shp_clf.shapelets_[m]
                np.savetxt("shapelet" + str(m) + ".txt", shap)
        print("Accuracy: {}".format(acc_new))
        cm_start += cm

np.savetxt("cm.txt", cm_start)

"""# 3. The visualisation"""

import re

''' functions allowing to load the shapelet data in the right order '''

def atof(text):
    try:
        retval = float(text)
    except ValueError:
        retval = text
    return retval

def natural_keys(text):
    return [ atof(c) for c in re.split(r'[+-]?([0-9]+(?:[.][0-9]*)?|[.][0-9]+)', text) ]


def shapelets_plot(nr, shapelets, dist, pred_loc):
    shap = np.loadtxt(shapelets[nr])
    dist_min = np.argmin(dist[:, nr])
    pos = int(pred_loc[dist_min, nr])
    shap = TimeSeriesScalerMinMax().fit_transform(shap.reshape(1, -1, 1)).flatten()

    return shap, dist_min, pos

"""<h3>a) Plotting the shapelets that best match to the time series (choice of the group of data to be visualized) </h3>"""

possibilities = ["naringenina", "voltage"]
choice = possibilities[0]

''' loading the data being a result of calculations performed in the previous steps '''

X_train = np.loadtxt("X_train.txt")
dist = np.loadtxt("dist.txt")
y_train = np.loadtxt("y_train.txt")
pred_loc = np.loadtxt("pred_loc.txt")
shapelets = glob("shapelet*.txt")
shapelets.sort(key=natural_keys)

if(choice == "naringenina"):
    labels = ["60_0", "60_10"]

elif(choice == "voltage"):
    labels = ["20_10", "60_10"]

''' Choice of the shapelets to be plotted '''

nr1 = 2
nr2 = 1

shap1, dist_min1, pos1 = shapelets_plot(nr1, shapelets, dist, pred_loc)
shap2, dist_min2, pos2 = shapelets_plot(nr2, shapelets, dist, pred_loc)

fig, ax = plt.subplots(2)
# sns.set(rc={'axes.facecolor':'white'})

ax[0].plot(X_train[dist_min1].ravel(), label="dwell time", color="#7FB4E7")
ax[0].plot(np.arange(pos1, pos1 + len(shap1)), shap1, linewidth=3, label="shapelet $s_{1}$", color="#2674BD")
ax[0].legend(loc=(0.01, 0.6), fontsize=12)
ax[0].set_xlabel("Number of state", fontsize=14)
ax[0].set_ylabel("N. state duration", fontsize=14)
ax[0].tick_params(axis='both', which='major', labelsize=12)


ax[1].plot(X_train[dist_min2].ravel(), label="dwell time", color="#7FB4E7")
ax[1].plot(np.arange(pos2, pos2 + len(shap2)), shap2, linewidth=3, label="shapelet $s_{2}$", color="#2674BD")
ax[1].legend(loc=(0.01, 0.6), fontsize=12)
ax[1].set_xlabel("Number of state", fontsize=14)
ax[1].set_ylabel("N. state duration", fontsize=14)
ax[1].tick_params(axis='both', which='major', labelsize=12)
plt.savefig("shapelets_naringenia.pdf", format="pdf", dpi=300)
fig.tight_layout()
plt.show()

"""<h3> c) Visualisation of data in the future space (the futures are the distances of time subseries to the given shapelets) </h3>"""

viridis = matplotlib.colormaps["tab10"]
k = 0

labels = [r"$U=20\;mV\quad \;[Nar]=10\;\mu M$", r"$U=60\;mV\quad[Nar]=10\;\mu M$"]

# Create a scatter plot of the 2D distances for the time series of each class.
for i, y in enumerate(np.unique(y_train)):
    plt.scatter(dist[y_train == y][:, nr1],
                    dist[y_train == y][:, nr2],
                    c=[viridis(i / 2)] * np.sum(y_train == y),
                    edgecolors='k',
                    label=labels[k])
    k+=1
plt.xlabel("d($x, s_{1}$)", fontweight='bold', fontsize=14)
plt.ylabel("d($x, s_{2}$)", fontweight='bold', fontsize=14)
plt.tick_params(axis='both', which='major', labelsize=12)
plt.legend()
plt.savefig("dist_naringenia.pdf", format="pdf", dpi=300)
plt.show()

"""# 4. Visitor Time Tracking with Live Camera

<h3> a) Visitor Tracking System </h3>
"""

class VisitorTracker:
    """
    Tracks visitors using live camera feed and calculates time spent by each visitor.
    """
    def __init__(self, camera_index=0, detection_method='face'):
        """
        Initialize visitor tracker.
        
        Parameters:
        - camera_index: Index of the camera (0 for default webcam)
        - detection_method: 'face' for face detection or 'person' for full body detection
        """
        self.camera_index = camera_index
        self.detection_method = detection_method
        self.visitors = {}  # Dictionary to store visitor information
        self.visitor_counter = 0
        self.active_visitors = {}  # Currently active visitors
        self.running = False
        
        # Initialize detection models
        if detection_method == 'face':
            # Load face detection model (Haar Cascade)
            cascade_path = cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
            self.detector = cv2.CascadeClassifier(cascade_path)
        else:
            # Load person detection model (HOG descriptor)
            self.hog = cv2.HOGDescriptor()
            self.hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())
        
        # Initialize camera
        self.cap = None
        
    def detect_visitors(self, frame):
        """
        Detect visitors in the frame.
        Returns list of bounding boxes (x, y, w, h) for detected visitors.
        """
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        detections = []
        
        if self.detection_method == 'face':
            faces = self.detector.detectMultiScale(gray, 1.1, 4)
            detections = [(x, y, w, h) for (x, y, w, h) in faces]
        else:
            # Person detection
            boxes, weights = self.hog.detectMultiScale(gray, winStride=(8, 8), padding=(32, 32), scale=1.05)
            detections = [(x, y, w, h) for (x, y, w, h) in boxes]
        
        return detections
    
    def calculate_iou(self, box1, box2):
        """
        Calculate Intersection over Union (IoU) of two bounding boxes.
        Used to match detections across frames.
        """
        x1, y1, w1, h1 = box1
        x2, y2, w2, h2 = box2
        
        # Calculate intersection
        xi1 = max(x1, x2)
        yi1 = max(y1, y2)
        xi2 = min(x1 + w1, x2 + w2)
        yi2 = min(y1 + h1, y2 + h2)
        
        inter_area = max(0, xi2 - xi1) * max(0, yi2 - yi1)
        
        # Calculate union
        box1_area = w1 * h1
        box2_area = w2 * h2
        union_area = box1_area + box2_area - inter_area
        
        iou = inter_area / union_area if union_area > 0 else 0
        return iou
    
    def match_detections(self, detections):
        """
        Match new detections with existing active visitors.
        Improved tracking with better ID persistence.
        """
        matched = set()
        matched_visitors = {}
        unmatched_existing = []
        
        # First pass: try to match existing visitors
        for visitor_id, visitor_data in self.active_visitors.items():
            visitor_box = visitor_data['box']
            best_iou = 0
            best_match = None
            
            for i, detection in enumerate(detections):
                if i in matched:
                    continue
                iou = self.calculate_iou(visitor_box, detection)
                if iou > best_iou and iou > 0.3:  # Threshold for matching
                    best_iou = iou
                    best_match = i
            
            if best_match is not None:
                matched.add(best_match)
                matched_visitors[visitor_id] = {
                    'box': detections[best_match],
                    'entry_time': visitor_data['entry_time'],
                    'last_seen': datetime.now()
                }
            else:
                # Visitor not detected - mark for potential removal
                unmatched_existing.append(visitor_id)
        
        # Remove visitors that haven't been seen for a while (they left)
        current_time = datetime.now()
        for visitor_id in unmatched_existing:
            visitor_data = self.active_visitors[visitor_id]
            # Only remove if not seen for more than 2 seconds
            if 'last_seen' in visitor_data:
                time_since_seen = (current_time - visitor_data['last_seen']).total_seconds()
                if time_since_seen > 2.0:  # 2 seconds threshold
                    # Visitor left - calculate total time
                    entry_time = visitor_data['entry_time']
                    exit_time = visitor_data.get('last_seen', current_time)
                    duration = (exit_time - entry_time).total_seconds()
                    
                    self.visitors[visitor_id] = {
                        'entry_id': visitor_id,
                        'entry_time': entry_time,
                        'exit_time': exit_time,
                        'duration_seconds': duration,
                        'duration_formatted': str(timedelta(seconds=int(duration)))
                    }
                else:
                    # Still tracking, just not detected this frame
                    matched_visitors[visitor_id] = {
                        'box': visitor_data['box'],
                        'entry_time': visitor_data['entry_time'],
                        'last_seen': visitor_data.get('last_seen', current_time)
                    }
            else:
                # First time not detected, mark last_seen
                matched_visitors[visitor_id] = {
                    'box': visitor_data['box'],
                    'entry_time': visitor_data['entry_time'],
                    'last_seen': current_time
                }
        
        # Add new visitors (unmatched detections)
        for i, detection in enumerate(detections):
            if i not in matched:
                self.visitor_counter += 1
                visitor_id = f"V{self.visitor_counter:04d}"  # Format: V0001, V0002, etc.
                matched_visitors[visitor_id] = {
                    'box': detection,
                    'entry_time': datetime.now(),
                    'last_seen': datetime.now()
                }
        
        # Update active visitors
        self.active_visitors = matched_visitors
    
    def format_time(self, seconds):
        """Format seconds into readable time string."""
        return str(timedelta(seconds=int(seconds)))
    
    def draw_info(self, frame):
        """Draw visitor information on the frame with improved ID display."""
        # Draw active visitors
        for visitor_id, visitor_data in self.active_visitors.items():
            x, y, w, h = visitor_data['box']
            entry_time = visitor_data['entry_time']
            duration = (datetime.now() - entry_time).total_seconds()
            
            # Draw bounding box with color based on duration
            color_intensity = min(255, int(duration * 10))  # Color gets brighter over time
            color = (0, 255 - color_intensity // 3, color_intensity // 3)
            cv2.rectangle(frame, (x, y), (x + w, y + h), color, 3)
            
            # Draw visitor ID with background for better visibility
            label = f"ID: {visitor_id}"
            time_label = f"Time: {self.format_time(duration)}"
            
            # Get text size for background
            font = cv2.FONT_HERSHEY_SIMPLEX
            font_scale = 0.7
            thickness = 2
            (text_width1, text_height1), _ = cv2.getTextSize(label, font, font_scale, thickness)
            (text_width2, text_height2), _ = cv2.getTextSize(time_label, font, font_scale, thickness)
            
            # Draw background rectangles
            cv2.rectangle(frame, (x, y - text_height1 - text_height2 - 15), 
                         (x + max(text_width1, text_width2) + 10, y), 
                         (0, 0, 0), -1)
            
            # Draw visitor ID
            cv2.putText(frame, label, (x + 5, y - text_height2 - 8), 
                       font, font_scale, (0, 255, 0), thickness)
            
            # Draw time
            cv2.putText(frame, time_label, (x + 5, y - 5), 
                       font, font_scale, (255, 255, 0), thickness)
        
        # Draw summary statistics with background
        total_visitors = len(self.visitors) + len(self.active_visitors)
        active_count = len(self.active_visitors)
        
        info_text = [
            f"Total Visitors: {total_visitors}",
            f"Active Now: {active_count}",
            f"Close window or press Ctrl+C to save data"
        ]
        
        # Draw background for text
        text_height = 30
        cv2.rectangle(frame, (5, 5), (400, len(info_text) * text_height + 10), 
                     (0, 0, 0), -1)
        
        y_offset = 30
        for text in info_text:
            cv2.putText(frame, text, (10, y_offset), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            y_offset += text_height
        
        return frame
    
    def run(self, use_matplotlib=True):
        """Run the visitor tracking system.
        
        Parameters:
        - use_matplotlib: If True, use matplotlib for display (works on Windows).
                          If False, try to use cv2.imshow (may not work on Windows).
        """
        self.cap = cv2.VideoCapture(self.camera_index)
        
        if not self.cap.isOpened():
            print(f"Error: Could not open camera {self.camera_index}")
            return
        
        print("Visitor tracking started. Press 'q' in the console to quit and save data.")
        print("Close the camera window to stop tracking.")
        self.running = True
        
        frame_count = 0
        detection_interval = 5  # Detect every 5 frames for performance
        
        # Setup matplotlib display if needed
        if use_matplotlib:
            plt.ion()  # Turn on interactive mode
            fig, ax = plt.subplots(figsize=(12, 8))
            ax.set_title('Visitor Time Tracker - Close window to stop', fontsize=14, fontweight='bold')
            ax.axis('off')
            img_display = None
        
        try:
            while self.running:
                ret, frame = self.cap.read()
                if not ret:
                    print("Error: Could not read frame from camera")
                    break
                
                frame_count += 1
                
                # Detect visitors periodically
                if frame_count % detection_interval == 0:
                    detections = self.detect_visitors(frame)
                    self.match_detections(detections)
                
                # Draw information on frame
                frame = self.draw_info(frame)
                
                # Display frame
                if use_matplotlib:
                    # Convert BGR to RGB for matplotlib
                    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                    
                    if img_display is None:
                        img_display = ax.imshow(frame_rgb)
                    else:
                        img_display.set_data(frame_rgb)
                    
                    # Update statistics text
                    total_visitors = len(self.visitors) + len(self.active_visitors)
                    active_count = len(self.active_visitors)
                    
                    # Clear previous text and add new info
                    for txt in ax.texts:
                        if txt.get_position()[1] < 0.05:  # Remove only info texts
                            txt.remove()
                    
                    info_text = (f"Total Visitors: {total_visitors} | "
                                f"Active Now: {active_count} | "
                                f"Press 'q' in console to quit")
                    ax.text(0.02, 0.02, info_text, transform=ax.transAxes,
                           fontsize=10, color='white', 
                           bbox=dict(boxstyle='round', facecolor='black', alpha=0.7))
                    
                    plt.draw()
                    plt.pause(0.01)  # Small pause to allow GUI to update
                    
                    # Check if window is closed
                    if not plt.get_fignums():
                        self.running = False
                        break
                else:
                    # Try cv2.imshow (may not work on Windows)
                    try:
                        cv2.imshow('Visitor Time Tracker', frame)
                        if cv2.waitKey(1) & 0xFF == ord('q'):
                            self.running = False
                            break
                    except cv2.error:
                        print("cv2.imshow not available, switching to matplotlib display...")
                        use_matplotlib = True
                        continue
                
                # Note: For console input, use Ctrl+C to stop
                # The matplotlib window close will also stop tracking
                        
        except KeyboardInterrupt:
            print("\nStopping visitor tracking...")
            self.running = False
        finally:
            # Finalize all active visitors
            current_time = datetime.now()
            for visitor_id, visitor_data in list(self.active_visitors.items()):
                entry_time = visitor_data['entry_time']
                duration = (current_time - entry_time).total_seconds()
                self.visitors[visitor_id] = {
                    'entry_time': entry_time,
                    'exit_time': current_time,
                    'duration_seconds': duration,
                    'duration_formatted': str(timedelta(seconds=int(duration)))
                }
            
            # Cleanup
            self.cap.release()
            if not use_matplotlib:
                try:
                    cv2.destroyAllWindows()
                except:
                    pass
            else:
                plt.ioff()
                plt.close('all')
        
        return self.visitors
    
    def save_to_csv(self, filename='visitor_times.csv'):
        """Save visitor time data to CSV file with improved formatting."""
        if not self.visitors:
            print("No visitor data to save.")
            return
        
        df_data = []
        for visitor_id, data in self.visitors.items():
            df_data.append({
                'Visitor_ID': visitor_id,
                'Entry_Time': data['entry_time'].strftime('%Y-%m-%d %H:%M:%S'),
                'Exit_Time': data['exit_time'].strftime('%Y-%m-%d %H:%M:%S'),
                'Duration_Seconds': round(data['duration_seconds'], 2),
                'Duration_Formatted': data['duration_formatted']
            })
        
        # Sort by entry time
        df = pd.DataFrame(df_data)
        df = df.sort_values('Entry_Time')
        df = df.reset_index(drop=True)
        
        df.to_csv(filename, index=False)
        print(f"\n{'='*60}")
        print(f"Visitor time data saved to {filename}")
        print(f"{'='*60}")
        print(f"\nSummary Statistics:")
        print(f"  Total visitors: {len(df)}")
        if len(df) > 0:
            print(f"  Average time: {df['Duration_Seconds'].mean():.2f} seconds ({str(timedelta(seconds=int(df['Duration_Seconds'].mean())))})")
            print(f"  Minimum time: {df['Duration_Seconds'].min():.2f} seconds")
            print(f"  Maximum time: {df['Duration_Seconds'].max():.2f} seconds")
            print(f"  Total time: {df['Duration_Seconds'].sum():.2f} seconds ({str(timedelta(seconds=int(df['Duration_Seconds'].sum())))})")
        print(f"\nDetailed Records:")
        print(f"{df.to_string(index=True)}")
        print(f"\n{'='*60}\n")

"""<h3> b) Run Visitor Tracking </h3>"""

def track_visitors(camera_index=0, detection_method='face', use_matplotlib=True):
    """
    Main function to run visitor tracking with live camera.
    
    Parameters:
    - camera_index: Camera device index (0 for default webcam)
    - detection_method: 'face' for face detection, 'person' for full body detection
    - use_matplotlib: If True, use matplotlib for display (recommended for Windows)
    """
    tracker = VisitorTracker(camera_index=camera_index, detection_method=detection_method)
    visitors = tracker.run(use_matplotlib=use_matplotlib)
    tracker.save_to_csv('visitor_times.csv')
    return visitors

# Uncomment the line below to run visitor tracking
# track_visitors(camera_index=0, detection_method='face')

"""<h3> c) Main Execution </h3>"""

if __name__ == "__main__":
    import sys
    
    # Check if visitor tracking is requested
    if len(sys.argv) > 1 and sys.argv[1] == '--track-visitors':
        camera_index = int(sys.argv[2]) if len(sys.argv) > 2 else 0
        detection_method = sys.argv[3] if len(sys.argv) > 3 else 'face'
        print("Starting visitor tracking with live camera...")
        print(f"Camera index: {camera_index}, Detection method: {detection_method}")
        track_visitors(camera_index=camera_index, detection_method=detection_method)
    else:
        print("To run visitor tracking, use: python shapelet_method.py --track-visitors [camera_index] [detection_method]")
        print("Example: python shapelet_method.py --track-visitors 0 face")
        print("\nRunning shapelet analysis (default behavior)...")
